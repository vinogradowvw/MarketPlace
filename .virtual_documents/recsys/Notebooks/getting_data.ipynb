!python3 -m spacy download en_core_web_sm


from datasets import load_dataset, Image
import pandas as pd
import numpy as np
import seaborn as sns
import spacy


posts = load_dataset("p1atdev/pinterest", split='train', )



posts_df = posts.to_pandas()
posts_df


posts_df.isna().sum()


posts_df.info()


posts_df.tags.apply(lambda x: len(x) == 0).sum()





np.sum(posts_df.alt.str.len() == 0)


sns.histplot(posts_df.alt.str.len())


posts_df.alt.str.len().describe()


nlp = spacy.load('en_core_web_sm')

def tokenize_and_lemmatize(string: str, nlp) -> str:
    doc = nlp(string)
    return (" ".join([token.lemma_.lower() for token in doc]))

def remove_non_alphabetic(string: str, nlp) -> str:
    return (" ".join(word for word in string.split(" ") if word.isalpha()))
    
posts_df.alt = posts_df.alt.apply(lambda x: tokenize_and_lemmatize(x, nlp))


posts_df.iloc[0]
